{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b5b402",
   "metadata": {},
   "source": [
    "Analyse de sentiment : l’objectif est de prédire la note (entre 1 et 0) à partir du texte de la revue d’un film, pour les données issues de la base de données IMDB (50000 revues sur des films, données accessibles sur http://ai.stanford.edu/~amaas/data/sentiment/) ; découper l’ensemble de données en données d’apprentissage et données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/malloc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/malloc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/malloc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "from sklearn.utils import shuffle\n",
    "nltk.download(['stopwords','punkt','averaged_perceptron_tagger'])\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed66be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab0d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(data):\n",
    "    data_d = [[str(i)] for i in  data['Text'].values[0:len(data)]]\n",
    "    return data_d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf40c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlabel(data):\n",
    "    label = [[float(i)] for i in  data['Sentiments'].values[0:len(data)]]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd41e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data):\n",
    "    d=[]\n",
    "    for sentence in getdata(data):\n",
    "        stop_words = stopwords.words('english')\n",
    "        wordwithoustop = ' '.join([word.lower() for word in word_tokenize(sentence[0]) if word not in stop_words + [string.punctuation]])\n",
    "        word_clean = wordwithoustop.replace(\"< br / >\", \"\").replace(\" '' `` \", \"\").replace(\")\", \"\").replace(\"(\",\"\").replace(\"``\", \"\") \\\n",
    "        .replace(\" , \", \",\").replace(\".   \", \".\").replace(\" . \", \".\").replace(\" 's\", \"'s\").replace(\" .\",\".\")\\\n",
    "        .replace(\"  \", \" \").replace(\".,\", \".\").replace(\" '' \", \" \").replace(\" : \", \":\").replace(\".\", \" \")\\\n",
    "        .replace(\",\", \" \").replace( \":\", \" \").replace(\";\", \" \").replace(\"{\", \" \").replace(\"}\", \" \").replace(\"--\", \" \")\\\n",
    "        .replace(\"'\", \" \").replace(\"!\",\" \").replace(\"!\", \" \").replace(\"/\", \" \").replace(\"-\", \" \").replace(\"*\", \" \")\n",
    "        l = WordNetLemmatizer()\n",
    "        lstem = [l.lemmatize(i) for i in word_tokenize(word_clean)]\n",
    "        d.append(\" \".join(lstem))\n",
    "    return pd.DataFrame(d,columns=['Text'])\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6496ea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>paul reiser step away standup comedy spotlight...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>ok start little gem ? mutant slug begin take s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>offbeat slow paced entertaining erotic thrille...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>the girl from missouri arrives new york city k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>i research film prior first viewing part welle...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>bradford dillman play scientist wake one morni...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23588</th>\n",
       "      <td>we n t television england i walked internet yo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>i glad i saw film seen director s film past i ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>all i say n t fall love big little edie watchi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22941</th>\n",
       "      <td>you know getting purchase hallmark card a sapp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  label\n",
       "2532   paul reiser step away standup comedy spotlight...    1.0\n",
       "15860  ok start little gem ? mutant slug begin take s...    0.0\n",
       "7957   offbeat slow paced entertaining erotic thrille...    1.0\n",
       "5619   the girl from missouri arrives new york city k...    1.0\n",
       "249    i research film prior first viewing part welle...    1.0\n",
       "...                                                  ...    ...\n",
       "13114  bradford dillman play scientist wake one morni...    0.0\n",
       "23588  we n t television england i walked internet yo...    0.0\n",
       "6138   i glad i saw film seen director s film past i ...    1.0\n",
       "3051   all i say n t fall love big little edie watchi...    1.0\n",
       "22941  you know getting purchase hallmark card a sapp...    0.0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = cleanData(data_train)\n",
    "dtrain['label'] = [i[0] for i in getlabel(data_train)]\n",
    "dtrain= shuffle(dtrain)\n",
    "dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef567ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = cleanData(data_test)\n",
    "dtest['label'] = [i[0] for i in getlabel(data_test)]\n",
    "dtest= shuffle(dtest)\n",
    "dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f6d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c21d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vect = TfidfVectorizer()\n",
    "X_train = trans_vect.fit_transform(dtrain['Text'])\n",
    "X_test = trans_vect.transform(dtest['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346bc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b35740",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train,dtrain['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb8c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuration:\", accuracy_score(dtest['label'],model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf7f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710e7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
